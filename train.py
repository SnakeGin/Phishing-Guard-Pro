import os
# è®¾ç½® Hugging Face å›½å†…é•œåƒç«™
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import os
import pandas as pd
from tqdm import tqdm
from datasets import load_dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# å¯¼å…¥ä½ çš„æ ¸å¿ƒæ¨¡å—
from feature_extractor import PhishingFeatureExtractor
from model_architecture import FMPEDModel, train_step_adversarial

# --- é…ç½®å‚æ•° ---
CONFIG = {
    "dataset_repo": "ealvaradob/phishing-dataset",
    "dataset_subset": "combined_reduced", # âš ï¸ å…³é”®ï¼šä½¿ç”¨ç²¾ç®€ç‰ˆä»¥ä¿è¯æ•°æ®å¹³è¡¡
    "max_samples": None,       # è®¾ä¸º None åˆ™ä½¿ç”¨å…¨é‡æ•°æ®ï¼Œè®¾ä¸ºæ•°å­—(å¦‚ 5000)åˆ™ç”¨äºå¿«é€Ÿæµ‹è¯•
    "batch_size": 32,
    "epochs": 5,               # çœŸå®æ•°æ®é‡å¤§ï¼ŒEpoch å¯ä»¥é€‚å½“å‡å°‘
    "learning_rate": 2e-5,     # BERT å¾®è°ƒé€šå¸¸éœ€è¦å¾ˆå°çš„å­¦ä¹ ç‡
    "model_save_path": "fmped_model.pth",
    "feature_cache_path": "features_cache_real.npz"
}

def load_dataset_strictly():
    """
    ä¸¥æ ¼å‚ç…§æ•°æ®é›†æ–‡æ¡£çš„åŠ è½½æ–¹å¼
    æ–‡æ¡£è¦æ±‚: dataset = load_dataset(..., "combined_reduced", ...)
    """
    print(f"ğŸŒ æ­£åœ¨è¿æ¥ HuggingFace ä¸‹è½½æ•°æ®é›†: {CONFIG['dataset_repo']} [{CONFIG['dataset_subset']}] ...")
    print("â„¹ï¸  æç¤º: æ–‡æ¡£å»ºè®®ä½¿ç”¨ 'combined_reduced' ä»¥é¿å… URL æ•°æ®å¸¦æ¥çš„ç±»åˆ«åå·®ã€‚")
    
    try:
        # 1. åŠ è½½æ•°æ®é›† (æ ¹æ®æ–‡æ¡£ï¼Œè¿™æ˜¯ä¸€ä¸ª DatasetDictï¼Œåªæœ‰ 'train' åˆ†æ”¯)
        dataset = load_dataset(
            CONFIG['dataset_repo'], 
            CONFIG['dataset_subset'], 
            trust_remote_code=True
        )
        
        # 2. è½¬æ¢ä¸º Pandas DataFrame
        df = dataset['train'].to_pandas()
        
        print("ğŸ“Š æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œæ­£åœ¨æ£€æŸ¥ç»“æ„...")
        # æ–‡æ¡£è¯´æ˜ç»“æ„: columns=['text', 'label'], label: 1(Phishing), 0(Benign)
        
        # 3. ç®€å•çš„æ•°æ®æ¸…æ´— (æ–‡æ¡£è¯´å·²ç»å»é‡å»ç©ºï¼Œè¿™é‡Œåšä¸ªå…œåº•æ£€æŸ¥)
        initial_len = len(df)
        df = df.dropna(subset=['text', 'label'])
        
        # 4. ç¡®ä¿æ ‡ç­¾æ˜¯æ•°å­—æ ¼å¼
        df['label'] = df['label'].astype(float)
        
        print(f"âœ… æ•°æ®å‡†å¤‡å°±ç»ª: {len(df)} æ¡æ ·æœ¬ (åŸå§‹: {initial_len})")
        print(f"   - é’“é±¼æ ·æœ¬ (1): {len(df[df['label']==1])}")
        print(f"   - æ­£å¸¸æ ·æœ¬ (0): {len(df[df['label']==0])}")
        
        # 5. é‡‡æ ·é™åˆ¶ (å¦‚æœé…ç½®äº† max_samples)
        if CONFIG['max_samples'] and len(df) > CONFIG['max_samples']:
            print(f"âœ‚ï¸ ä»…ä½¿ç”¨å‰ {CONFIG['max_samples']} æ¡æ•°æ®è¿›è¡Œè®­ç»ƒ (é…ç½®é™åˆ¶)...")
            # ä¿æŒåˆ†å±‚é‡‡æ ·ä»¥ç»´æŒå¹³è¡¡
            df = df.groupby('label', group_keys=False).apply(
                lambda x: x.sample(min(len(x), CONFIG['max_samples'] // 2), random_state=42)
            )
            # æ‰“ä¹±
            df = df.sample(frac=1, random_state=42).reset_index(drop=True)

        return df['text'].tolist(), df['label'].tolist()

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½ä¸¥é‡é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– huggingface åº“ç‰ˆæœ¬ (pip install --upgrade datasets)")
        exit(1)

def extract_features_robust(texts, labels, extractor):
    """
    ç‰¹å¾æå–é€»è¾‘è°ƒæ•´ï¼š
    è¯¥æ•°æ®é›†æ˜¯æ··åˆç±»å‹çš„ (URL, SMS, HTML, Email)ï¼Œ
    æˆ‘ä»¬éœ€è¦è®©æå–å™¨å°½å¯èƒ½å¤šåœ°æŒ–æ˜ä¿¡æ¯ã€‚
    """
    if os.path.exists(CONFIG['feature_cache_path']):
        print(f"ğŸ’¾ å‘ç°ç¼“å­˜ç‰¹å¾ '{CONFIG['feature_cache_path']}'ï¼Œæ­£åœ¨åŠ è½½...")
        data = np.load(CONFIG['feature_cache_path'])
        if len(data['y']) == len(labels):
            print("âœ… ç¼“å­˜æ ¡éªŒé€šè¿‡ï¼Œè·³è¿‡ BERT æå–ã€‚")
            return data['X'], data['y']
        else:
            print("âš ï¸ ç¼“å­˜æ•°é‡ä¸åŒ¹é…ï¼Œé‡æ–°æå–...")

    print("ğŸš€ å¼€å§‹å¤šæ¨¡æ€ç‰¹å¾æå– (Pipeline)...")
    features_list = []
    valid_labels = []
    
    # è¿›åº¦æ¡
    for i, content in enumerate(tqdm(texts, desc="Processing")):
        try:
            content_str = str(content)
            
            # --- å…³é”®ç­–ç•¥è°ƒæ•´ ---
            # å› ä¸ºæ•°æ®é›†ä¸­æœ‰äº›è¡Œæ˜¯çº¯ HTML ä»£ç ï¼Œæœ‰äº›æ˜¯çº¯ URLï¼Œæœ‰äº›æ˜¯çº¯æ–‡æœ¬ã€‚
            # æˆ‘ä»¬å°† content åŒæ—¶ä¼ ç»™ raw_text å’Œ html_contentã€‚
            # 1. å¦‚æœå®ƒæ˜¯ HTMLï¼ŒBS4 ä¼šè§£æå‡º tag ç‰¹å¾ã€‚
            # 2. å¦‚æœå®ƒæ˜¯ URLï¼Œæ­£åˆ™ä¼šæå–å‡º URL ç‰¹å¾ã€‚
            # 3. BERT ä¼šè¯»å–åŸæ–‡æå–è¯­ä¹‰ã€‚
            
            # æˆªæ–­è¿‡é•¿æ–‡æœ¬é˜²æ­¢å†…å­˜çˆ†ç‚¸ (ç‰¹åˆ«æ˜¯ HTML ä»£ç å¯èƒ½å¾ˆé•¿)
            truncated_content = content_str[:10000] 
            
            result = extractor.process_email(
                raw_text=truncated_content, 
                html_content=truncated_content 
            )
            
            features_list.append(result['fused_vector'])
            valid_labels.append(labels[i])
            
        except Exception as e:
            # å®¹é”™å¤„ç†ï¼Œæ‰“å°é”™è¯¯ä½†ä¸åœæœº
            # print(f"âš ï¸ Error processing sample {i}: {e}")
            continue

    X = np.array(features_list, dtype=np.float32)
    y = np.array(valid_labels, dtype=np.float32)
    
    print(f"ğŸ’¾ ç¼“å­˜ç‰¹å¾åˆ° {CONFIG['feature_cache_path']} ...")
    np.savez(CONFIG['feature_cache_path'], X=X, y=y)
    
    return X, y

def evaluate(model, loader, device):
    model.eval()
    all_preds, all_targets = [], []
    with torch.no_grad():
        for x, y in loader:
            outputs = model(x)
            preds = (outputs > 0.5).float()
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(y.cpu().numpy())
    
    acc = accuracy_score(all_targets, all_preds)
    # average='binary' é€‚ç”¨äºäºŒåˆ†ç±»
    p, r, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='binary')
    return acc, p, r, f1

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âš™ï¸ è®¡ç®—è®¾å¤‡: {device}")
    
    # 1. åŠ è½½æ•°æ® (Combined Reduced Dataset)
    texts, labels = load_dataset_strictly()
    
    # 2. åˆå§‹åŒ–æå–å™¨
    print("ğŸ§  åˆå§‹åŒ– BERT ç‰¹å¾æå–å™¨...")
    extractor = PhishingFeatureExtractor()
    
    # 3. æå–ç‰¹å¾ (å«ç¼“å­˜æœºåˆ¶)
    X_data, y_data = extract_features_robust(texts, labels, extractor)
    
    # 4. åˆ’åˆ†æ•°æ®é›† (æ–‡æ¡£å»ºè®®: 80% Train, 20% Test)
    # ä½¿ç”¨ stratify ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„é»‘ç™½æ ·æœ¬æ¯”ä¾‹ä¸€è‡´
    X_train, X_test, y_train, y_test = train_test_split(
        X_data, y_data, test_size=0.2, random_state=42, stratify=y_data
    )
    
    # 5. å°è£… DataLoader
    train_ds = TensorDataset(torch.tensor(X_train).to(device), torch.tensor(y_train).unsqueeze(1).to(device))
    test_ds = TensorDataset(torch.tensor(X_test).to(device), torch.tensor(y_test).unsqueeze(1).to(device))
    
    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True)
    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False)
    
    # 6. æ¨¡å‹åˆå§‹åŒ–
    print("ğŸ—ï¸ æ„å»º FMPED æ¨¡å‹...")
    model = FMPEDModel().to(device)
    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])
    criterion = nn.BCELoss() # äºŒåˆ†ç±»äº¤å‰ç†µ
    
    # 7. è®­ç»ƒå¾ªç¯
    print(f"âš”ï¸ å¼€å§‹å…¨é‡è®­ç»ƒ (Epochs: {CONFIG['epochs']}) ...")
    best_f1 = 0.0
    
    for epoch in range(CONFIG['epochs']):
        model.train()
        total_loss = 0
        
        for batch_x, batch_y in train_loader:
            # æ··åˆä½¿ç”¨æ™®é€šè®­ç»ƒå’Œå¯¹æŠ—è®­ç»ƒ
            # è¿™é‡Œæˆ‘ä»¬æ¯æ­¥éƒ½ä½¿ç”¨å¯¹æŠ—è®­ç»ƒæ¥å¢å¼ºæ¨¡å‹å¯¹å¾®å°æ‰°åŠ¨çš„é²æ£’æ€§
            loss = train_step_adversarial(model, optimizer, batch_x, batch_y, epsilon=0.03)
            total_loss += loss
            
        avg_loss = total_loss / len(train_loader)
        
        # éªŒè¯
        acc, prec, rec, f1 = evaluate(model, test_loader, device)
        
        print(f"[Epoch {epoch+1}] Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if f1 > best_f1:
            best_f1 = f1
            torch.save(model.state_dict(), CONFIG['model_save_path'])
            print(f"    ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (F1: {best_f1:.4f})")

    print("\nâœ… è®­ç»ƒç»“æŸã€‚è¯·é‡å¯ main.py ä»¥åŠ è½½æ–°æ¨¡å‹ã€‚")

if __name__ == "__main__":
    main()