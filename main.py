from fastapi import UploadFile, File, FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from email import policy
from email.parser import BytesParser
from pydantic import BaseModel
from typing import Optional, List
import torch
import uvicorn
import httpx
import os
import json
import datetime
import re
from bs4 import BeautifulSoup # å¼•å…¥ BS4 ç”¨äºHTMLå–è¯åˆ†æ

# --- æ•°æ®åº“ç›¸å…³å¯¼å…¥ ---
from sqlalchemy import create_engine, Column, Integer, String, Float, Text, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from feature_extractor import PhishingFeatureExtractor
from model_architecture import FMPEDModel

# ==========================================
# âš™ï¸ é…ç½®åŒºåŸŸ
# ==========================================
LLM_API_KEY = "sk-genwnvgxggzilqhrkgmelgiylwskasedyemtzxadenqfgykx" 
LLM_API_URL = "https://api.siliconflow.cn/v1/chat/completions" 
# LLM_MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"
LLM_MODEL_NAME = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
DATABASE_URL = "sqlite:///./phishing_logs.db" 

# --- 1. æ•°æ®åº“åˆå§‹åŒ– ---
Base = declarative_base()

class DetectionRecord(Base):
    __tablename__ = "records"
    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String, index=True)
    risk_score = Column(Float)
    verdict = Column(String)
    risk_level = Column(String)
    features_json = Column(Text)
    defense_suggestion = Column(Text)
    email_content = Column(Text)
    forensic_data = Column(Text) # <--- [æ–°å¢] å­˜å‚¨è¯¦ç»†å–è¯åˆ—è¡¨(JSONå­—ç¬¦ä¸²)
    created_at = Column(DateTime, default=datetime.datetime.now)

engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base.metadata.create_all(bind=engine)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# --- 2. FastAPI åˆå§‹åŒ– ---
app = FastAPI(title="MH-PDS Backend Pro", version="3.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

model_engine = {}
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- 3. æ•°æ®æ¨¡å‹ ---
class HistoryItem(BaseModel):
    id: int
    filename: str
    risk_score: float
    verdict: str
    risk_level: str
    created_at: str
    features_summary: dict
    email_content: Optional[str] = ""
    defense_suggestion: Optional[str] = ""
    forensic_data: List[str] = [] # <--- [æ–°å¢] è¿”å›ç»™å‰ç«¯çš„è¯æ®åˆ—è¡¨

    class Config:
        orm_mode = True

class AnalysisResult(BaseModel):
    id: int
    risk_score: float
    verdict: str
    risk_level: str
    features_summary: dict
    defense_suggestion: str
    email_content: str
    forensic_data: List[str] # <--- [æ–°å¢]
    processing_time: float

# --- 4. ç”Ÿå‘½å‘¨æœŸ ---
@app.on_event("startup")
async def startup_event():
    print(f"ğŸš€ ç³»ç»Ÿå¯åŠ¨ä¸­... è¿è¡Œè®¾å¤‡: {DEVICE}")
    model_engine['extractor'] = PhishingFeatureExtractor()
    try:
        fmped_model = FMPEDModel().to(DEVICE)
        fmped_model.load_state_dict(torch.load("fmped_model.pth", map_location=DEVICE))
        fmped_model.eval()
        model_engine['detector'] = fmped_model
        print("âœ… çœŸå®æ¨¡å‹ (FMPED) åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e} (å°†ä½¿ç”¨æ¼”ç¤ºé€»è¾‘)")
        model_engine['detector'] = None

# --- 5. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

# [æ–°å¢] è¯¦ç»†å–è¯ç”Ÿæˆå™¨
def generate_forensic_report(text_content, html_content):
    """
    æ‰«æå†…å®¹ï¼Œæå–å…·ä½“çš„â€œç½ªè¯â€å­—ç¬¦ä¸²ï¼Œç”¨äºå‰ç«¯å±•ç¤º
    """
    evidence = []
    
    # 1. æ‰«ææ•æ„Ÿè¯ (æå–ä¸Šä¸‹æ–‡)
    # å®šä¹‰é«˜å±è¯åº“
    keywords = ["ç«‹å³", "24å°æ—¶", "å†»ç»“", "suspend", "urgent", "verify", "login", "password", "bank", "refund", "å¸æˆ·", "å¼‚å¸¸", "ç«‹å³", "24å°æ—¶", "å†»ç»“", "suspend", "urgent", "immediate", "breach","ç‚¹å‡»", "ç™»å½•", "éªŒè¯", "verify", "login", "click here", "update", "sign in","é“¶è¡Œ", "é€€ç¨", "ä¸­å¥–", "bank", "refund", "invoice", "payment", "winner"]
    hits = []
    text_lower = text_content.lower()
    for kw in keywords:
        if kw in text_lower:
            hits.append(kw)
    if hits:
        # å»é‡å¹¶åªå–å‰5ä¸ª
        unique_hits = list(set(hits))[:5]
        evidence.append(f"âš ï¸ å‘ç° {len(hits)} ä¸ªé«˜å±è¯±å¯¼è¯: {', '.join(unique_hits)}...")

    # 2. æ‰«æ IP ç›´è¿é“¾æ¥
    ip_pattern = re.compile(r'http[s]?://(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    ip_links = ip_pattern.findall(text_content)
    for ip in list(set(ip_links))[:3]: # åªå±•ç¤ºå‰3ä¸ªå»é‡IP
        evidence.append(f"ğŸš« æ£€æµ‹åˆ°è£¸ IP é“¾æ¥ (ç»•è¿‡åŸŸåæ£€æµ‹): {ip}")

    # 3. æ‰«æ HTML ç‰¹å¾
    if html_content:
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 3.1 éšè— iframe
            hidden_iframes = soup.find_all('iframe', attrs={"style": re.compile(r'display:\s*none|visibility:\s*hidden')})
            small_iframes = soup.find_all('iframe', width="0", height="0")
            if hidden_iframes or small_iframes:
                evidence.append("ğŸ•µï¸â€â™‚ï¸ æ£€æµ‹åˆ°ä¸å¯è§ Iframe æ ‡ç­¾ (å¯èƒ½åŒ…å« Drive-by Download æ”»å‡»)")
                
            # 3.2 å¯†ç è¡¨å•
            password_inputs = soup.find_all('input', type='password')
            if password_inputs:
                evidence.append("ğŸ”“ æ£€æµ‹åˆ°éæ³•çš„å¯†ç æ”¶é›†è¡¨å• (Credential Harvesting)")
                    
            # 3.3 é“¾æ¥ä¸ä¸€è‡´ (Link Mismatch)
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥ï¼Œçœ‹æ–‡æœ¬å’Œhrefæ˜¯å¦å·®å¼‚å·¨å¤§
            links = soup.find_all('a', href=True)
            for link in links:
                visible = link.get_text().strip()
                href = link['href']
                
                # å¦‚æœæ˜¾ç¤ºçš„æ–‡æœ¬åƒä¸ªåŸŸåï¼Œä½†hrefä¸åŒ…å«å®ƒ
                if re.match(r'^(http|www)', visible):
                    # ç®€å•æå–åŸŸåæ¯”è¾ƒ
                    visible_clean = visible.replace('https://', '').replace('http://', '').split('/')[0]
                    if len(visible_clean) > 5 and visible_clean not in href:
                        evidence.append(f"ğŸ£ å‘ç°â€œè¡¨é‡Œä¸ä¸€â€çš„æ¬ºè¯ˆé“¾æ¥: æ˜¾ç¤º '{visible[:30]}' ä½†æŒ‡å‘ '{href[:30]}...'")
                        break # åªæŠ¥ä¸€ä¸ªå…¸å‹
        except:
            pass # HTMLè§£æå®¹é”™

    if not evidence:
        evidence.append("âœ… æœªæ£€æµ‹åˆ°å…·ä½“çš„ç¡¬ç‰¹å¾æŒ‡çº¹ (å¯èƒ½æ˜¯çº¯è¯­ä¹‰æ”»å‡»)")
        
    return evidence

async def generate_real_ai_advice(risk_score: float, details: dict, email_text: str) -> str:
    verdict = "é«˜å±é’“é±¼é‚®ä»¶" if risk_score > 75 else "å¯ç–‘é‚®ä»¶" if risk_score > 45 else "å®‰å…¨é‚®ä»¶"
    email_snippet = email_text[:1000].replace('\n', ' ')
    
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªç½‘ç»œå®‰å…¨ä¸“å®¶ã€‚è¯·æ ¹æ®æ£€æµ‹æ•°æ®ç”Ÿæˆä¸€ä»½ç®€çŸ­é˜²å¾¡å»ºè®®ã€‚ä¸è¦åŒ…å«Markdownæ ‡é¢˜(#)ï¼Œç›´æ¥åˆ†ç‚¹è¯´æ˜é£é™©å’Œå»ºè®®ã€‚"
    user_prompt = f"""
    ç»“æœ: {verdict} (åˆ†å€¼: {risk_score})
    ç‰¹å¾: {json.dumps(details, ensure_ascii=False)}
    é‚®ä»¶: {email_snippet}...
    è¯·ç»™å‡ºçº¦150å­—çš„åˆ†æä¸å»ºè®®ã€‚
    """

    if "sk-xxx" in LLM_API_KEY:
        return generate_fallback_advice(risk_score, details)

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            payload = {
                "model": LLM_MODEL_NAME,
                "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                "temperature": 0.3
            }
            response = await client.post(LLM_API_URL, json=payload, headers={"Authorization": f"Bearer {LLM_API_KEY}"})
            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content']
    except Exception as e:
        print(f"âŒ LLM Error: {e}")
        return generate_fallback_advice(risk_score, details)

def generate_fallback_advice(score, details):
    return "æ— æ³•è¿æ¥AIæœåŠ¡ã€‚å»ºè®®ï¼šä¸è¦ç‚¹å‡»ä»»ä½•é“¾æ¥ï¼Œå‘ITéƒ¨é—¨æ ¸å®ã€‚"

def parse_eml_content(file_bytes: bytes):
    msg = BytesParser(policy=policy.default).parsebytes(file_bytes)
    subject = msg.get('subject', 'æ— ä¸»é¢˜')
    text_content = ""
    html_content = ""
    if msg.get_body(preferencelist=('plain')): text_content = msg.get_body(preferencelist=('plain')).get_content()
    if msg.get_body(preferencelist=('html')): html_content = msg.get_body(preferencelist=('html')).get_content()
    if not text_content and html_content:
        from bs4 import BeautifulSoup
        text_content = BeautifulSoup(html_content, "html.parser").get_text()
    if not text_content:
         for part in msg.walk():
            if part.get_content_type() == "text/plain": text_content += part.get_content()
    return subject, text_content, html_content

# --- 6. API æ¥å£ ---

@app.get("/api/history", response_model=List[HistoryItem])
def read_history(skip: int = 0, limit: int = 20, db: Session = Depends(get_db)):
    records = db.query(DetectionRecord).order_by(DetectionRecord.created_at.desc()).offset(skip).limit(limit).all()
    results = []
    for r in records:
        item = HistoryItem(
            id=r.id,
            filename=r.filename,
            risk_score=r.risk_score,
            verdict=r.verdict,
            risk_level=r.risk_level,
            created_at=r.created_at.strftime("%Y-%m-%d %H:%M"),
            features_summary=json.loads(r.features_json) if r.features_json else {},
            email_content=r.email_content or "æ— å†…å®¹",
            defense_suggestion=r.defense_suggestion or "æš‚æ— å»ºè®®",
            # [æ–°å¢] è§£æ JSON åˆ—è¡¨ï¼Œå¦‚æœä¸ºç©ºåˆ™è¿”å›ç©ºåˆ—è¡¨
            forensic_data=json.loads(r.forensic_data) if r.forensic_data else [] 
        )
        results.append(item)
    return results

@app.post("/api/analyze-file", response_model=AnalysisResult)
async def analyze_email_file(file: UploadFile = File(...), db: Session = Depends(get_db)):
    import time
    start_time = time.time()
    
    content = await file.read()
    subject, text_content, html_content = parse_eml_content(content)
    
    extractor = model_engine['extractor']
    detector = model_engine['detector']
    
    html_input = html_content if html_content else text_content
    # æ³¨æ„ï¼šç‰¹å¾æå–éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œè®­ç»ƒæ—¶å¦‚æœåªç”¨äº†ä¸€ä¸ªï¼Œè¿™é‡Œè¦ä¿æŒä¸€è‡´
    feature_data = extractor.process_email(text_content[:5000], html_input[:5000])
    
    # [æ–°å¢] ç”Ÿæˆè¯¦ç»†å–è¯æ•°æ®
    forensic_evidence = generate_forensic_report(text_content, html_input)

    risk_score = 0.0
    if detector:
        input_tensor = torch.tensor(feature_data['fused_vector'], dtype=torch.float32).unsqueeze(0).to(DEVICE)
        with torch.no_grad():
            raw_score = detector(input_tensor).item() * 100
            
            # æƒé‡ä¿®æ­£é€»è¾‘
            feats = feature_data['details']
            hard_evidence_count = feats.get('url_count', 0) + (1 if feats.get('has_iframe') else 0) + (1 if feats.get('suspicious_ip_urls', 0) > 0 else 0)
            
            if hard_evidence_count == 0:
                risk_score = raw_score * 0.6 
            else:
                risk_score = raw_score
    else:
        risk_score = 88.5

    if risk_score > 75: verdict, risk_level = "Phishing", "High"
    elif risk_score > 45: verdict, risk_level = "Suspicious", "Medium"
    else: verdict, risk_level = "Safe", "Low"
    
    suggestion = await generate_real_ai_advice(risk_score, feature_data['details'], text_content)
    
    db_record = DetectionRecord(
        filename=file.filename,
        risk_score=risk_score,
        verdict=verdict,
        risk_level=risk_level,
        features_json=json.dumps(feature_data['details']),
        defense_suggestion=suggestion,
        email_content=html_input,
        forensic_data=json.dumps(forensic_evidence) # [æ–°å¢] å­˜å…¥æ•°æ®åº“
    )
    db.add(db_record)
    db.commit()
    db.refresh(db_record)
    
    process_time = time.time() - start_time
    
    return {
        "id": db_record.id,
        "risk_score": round(risk_score, 2),
        "verdict": verdict,
        "risk_level": risk_level,
        "features_summary": feature_data['details'],
        "defense_suggestion": suggestion,
        "email_content": html_input,
        "forensic_data": forensic_evidence, # [æ–°å¢] è¿”å›ç»™å‰ç«¯
        "processing_time": round(process_time, 3)
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)